[
    {
        "question": "Mapper implementations are passed the JobConf for the job via the ________ method.",
        "options": [
            "a) JobConfigure.configure",
            "b) JobConfigurable.configure",
            "c) JobConfigurable.configurable",
            "d) None of the mentioned"
        ],
        "answer": "b",
        "explanation": "JobConfigurable.configure method is overridden to initialize themselves."
    },
    {
        "question": "Point out the correct statement.",
        "options": [
            "a) Applications can use the Reporter to report progress",
            "b) The Hadoop MapReduce framework spawns one map task for each InputSplit generated by the InputFormat for the job",
            "c) The intermediate, sorted outputs are always stored in a simple (key-len, key, value-len, value) format",
            "d) All of the mentioned"
        ],
        "answer": "d",
        "explanation": "Reporters can be used to set application-level status messages and update Counters."
    },
    {
        "question": "Input to the _______ is the sorted output of the mappers.",
        "options": [
            "a) Reducer",
            "b) Mapper",
            "c) Shuffle",
            "d) All of the mentioned"
        ],
        "answer": "a",
        "explanation": "In the Shuffle phase the framework fetches the relevant partition of the output of all the mappers, via HTTP."
    },
    {
        "question": "The right number of reduces seems to be ____________",
        "options": [
            "a) 0.90",
            "b) 0.80",
            "c) 0.36",
            "d) 0.95"
        ],
        "answer": "d",
        "explanation": "The right number of reduces seems to be 0.95 or 1.75."
    },
    {
        "question": "Point out the wrong statement.",
        "options": [
            "a) Reducer has 2 primary phases",
            "b) Increasing the number of reduces increases the framework overhead, but increases load balancing and lowers the cost of failures",
            "c) It is legal to set the number of reduce-tasks to zero if no reduction is desired",
            "d) The framework groups Reducer inputs by keys (since different mappers may have output the same key) in the sort stage"
        ],
        "answer": "a",
        "explanation": "Reducer has 3 primary phases: shuffle, sort and reduce."
    },
    {
        "question": "The output of the _______ is not sorted in the Mapreduce framework for Hadoop.",
        "options": [
            "a) Mapper",
            "b) Cascader",
            "c) Scalding",
            "d) None of the mentioned"
        ],
        "answer": "d",
        "explanation": "The output of the reduce task is typically written to the FileSystem. The output of the Reducer is not sorted."
    },
    {
        "question": "Mapper and Reducer implementations can use the ________ to report progress or just indicate that they are alive.",
        "options": [
            "a) Partitioner",
            "b) OutputCollector",
            "c) Reporter",
            "d) All of the mentioned"
        ],
        "answer": "c",
        "explanation": "Reporter is a facility for MapReduce applications to report progress, set application-level status messages and update Counters."
    },
    {
        "question": "__________ is a generalization of the facility provided by the MapReduce framework to collect data output by the Mapper or the Reducer.",
        "options": [
            "a) Partitioner",
            "b) OutputCollector",
            "c) Reporter",
            "d) All of the mentioned"
        ],
        "answer": "b",
        "explanation": "Hadoop MapReduce comes bundled with a library of generally useful mappers, reducers, and partitioners."
    },
    {
        "question": "_________ is the primary interface for a user to describe a MapReduce job to the Hadoop framework for execution.",
        "options": [
            "a) Map Parameters",
            "b) JobConf",
            "c) MemoryConf",
            "d) None of the mentioned"
        ],
        "answer": "b",
        "explanation": "JobConf represents a MapReduce job configuration."
    }
]